# -*- coding: utf-8 -*-
"""Capstone_Hacktiv8_IBM_Davina Icasia

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1A-Bd9hwo1w0__SV3rhEkdEcFdYy2E_6g

## Data Cleaning
"""

import pandas as pd
import numpy as np

# Data Restaurant Customer
df = pd.read_csv("/content/Restaurant_Reviews.csv")
df.head()

# Dataset Attributes Information
df.info()

# Pemeriksaan Missing Values
for i in df.columns:
  print(f"{i} null sum: {df[i].isnull().sum()}")

# Deteksi Duplikasi Data
print(df.duplicated().sum())

# Menghapus Duplikasi Data
df = df.drop_duplicates()

# Cek Kembali
print(df.duplicated().sum())

# Menghapus Karakter Tidak Digunakan
df['Review'] = df['Review'].str.replace(r'\s+', ' ', regex=True).str.strip()

df.head()

# Menyimpan Dataset Bersih
df.to_csv("Dataset_Bersih_RestaurantReview.csv", index=False)
print("Dataset Bersih telah disimpan dalam 'Dataset_Bersih_RestaurantReview.csv'")

"""## LAB 1"""

!pip install langchain_community
!pip install replicate

from langchain_community.llms import Replicate
import os
from google.colab import userdata

# Setup
api_token = userdata.get('api_token')
os.environ["REPLICATE_API_TOKEN"] = api_token

llm = Replicate(
    model="ibm-granite/granite-3.3-8b-instruct",
    replicate_api_token=api_token
)

# Load dataset bersih
df = pd.read_csv("Dataset_Bersih_RestaurantReview.csv")
df.head()

# Ambil 3 review acak
sample_reviews = df['Review'].dropna().sample(3, random_state=42).tolist()
reviews_text = "\n".join([f"Review {i+1}: {text}" for i, text in enumerate(sample_reviews)])

# Prompt Dasar
prompt = f"""
Classify these reviews as Positive, Negative, or Mixed:
{reviews_text}
"""
response = llm.invoke(prompt)
print("Response (Basic Prompt):\n", response)

# Refined prompt
refined_prompt = f"""
Classify these restaurant reviews as positive, negative, or mixed,
and tag relevant aspects such as food, service, price, cleanliness:

{reviews_text}
"""
response = llm.invoke(refined_prompt)
print("\nResponse (Refined Prompt):\n", response)

# Multitask Prompt
multitask_prompt = f"""
Complete this task in 2 steps.
Step 1: Classify each restaurant review as positive, negative, or mixed.
Step 2: Identify relevant aspects: food, service, price, cleanliness.

{reviews_text}
"""
response = llm.invoke(multitask_prompt)
print("Response (Multitask):\n", response)

# Formatted Prompt
formatted_prompt = f"""
Classify these restaurant reviews as Positive, Negative, or Mixed, and tag relevant aspects.
Use this format:
- Sentiment: [Sentiment]
- Aspects: [List of Aspects]

{reviews_text}
"""
response = llm.invoke(formatted_prompt)
print("Response (Formatted):\n", response)

# Ambil 8 review acak dari dataset bersih
sample_reviews = df['Review'].dropna().sample(8, random_state=99).tolist()
reviews_text = "\n".join([f"- {text}" for text in sample_reviews])

# Prompt Terstruktur
refined_outputformat_prompt = f"""
Analyze the following restaurant reviews and summarize the key takeaways
using this structured format:

Key Feedback:
- [Highlight common opinions or themes]

Customer Sentiment:
- [Summarize the overall tone of the reviews]

Improvement Suggestions:
- [What could be improved according to the reviews]

Reviews:
{reviews_text}
"""

response = llm.invoke(refined_outputformat_prompt)
print("Granite Model Summary Output:\n")
print(response)

"""## LAB 2"""

# Ambil 5 Sample Review Secara Acak
sample_reviews = df['Review'].dropna().sample(5, random_state=7).tolist()
reviews_text = "\\n".join([f"- {text}" for text in sample_reviews])

# PROMPT: CLASSIFICATION
classification_prompt = f"""
Classify these restaurant reviews as positive, negative, or mixed,
and tag relevant aspects: food, service, price, cleanliness.

{reviews_text}
"""

# PROMPT: SUMMARIZATION
refined_focus_prompt = f"""
Summarize the following restaurant reviews by focusing on:
- Key Feedback (what customers often mention)
- Customer Sentiment (tone of the reviews)
- Suggestions for Improvement (what needs to be improved)

{reviews_text}
"""

# Default Parameters
parameters = {
    "top_k": 0,
    "top_p": 1.0,
    "max_tokens": 256,
    "min_tokens": 0,
    "random_seed": None,
    "repetition_penalty": 1.0,
    "stopping_criteria": "length",
    "stopping_sequence": None
}

# Parameter Sets to Explore
parameter_sets = [
    {"top_k": 5, "top_p": 1.0, "max_tokens": 256, "min_tokens": 0, "repetition_penalty": 1.0},
    {"top_k": 1, "top_p": 0.5, "max_tokens": 10, "min_tokens": 3, "repetition_penalty": 1.5},
    {"top_k": 1, "top_p": 0.5, "max_tokens": 3,  "min_tokens": 1, "repetition_penalty": 1.5},
]

# === CLASSIFICATION PROMPT ===
for i, param_set in enumerate(parameter_sets):
    print(f"--- Classification | Parameter Set {i+1} ---")
    full_params = parameters.copy()
    full_params.update(param_set)
    response = llm.invoke(classification_prompt, parameters=full_params)
    print(response)
    print("-" * 50)

# === SUMMARIZATION PROMPT ===
for i, param_set in enumerate(parameter_sets):
    print(f"--- Summarization | Parameter Set {i+1} ---")
    full_params = parameters.copy()
    full_params.update(param_set)
    response = llm.invoke(refined_focus_prompt, parameters=full_params)
    print(response)
    print("-" * 50)